The overall approach to my implementation of the SPIMI indexer relies heavily upon a reliance on object-oriented design.
Almost everything since entity involved with this program has been encapsulated within a unique class, with the primary
user access-points exposed by the query and spimi python files with common utility classes stored in the core.py file.

#Installation:
To install the program, simply clone the git repo to the desired folder and run the following command from the root of the main folder to install the required packages:
pip install -r requirements.txt

#Application Description and Utilization

This application assumes that the user has already downloaded and extracted the proper corpus to a given location located
in relative proximity to the location of the application. From this point the user calls the spimi.py file with the desired parameters
to define memory-block size in MB and the various compression techniques (options are: case-folding, digit removal, stopword removal, and Porter stemming).

##Index Creation:
Example commandline:python spimi.py -S 2000 -c -d -m -s
HELP DIALOG
  -h, --help            show this help message and exit
  -d, --digits          Enable digit removal dictionary compression
  -c, --case            Enable case folding dictionary compression
  -s, --stopwords       Enable stopword removal dictionary compression
  -m, --stemmer         Enable Porter Stemmer usage for dictionary compression
  -S SIZE, --size SIZE  Block size in MB to simulate memory restrictions


Once the program begins execution it finds all files with the .sgm file type in the targeted corpus folder and begins iteratively parsing each file into its component articles,
which are represented by Document class objects. These objects parse the entirety of the article during construction, extracting the article Id,
topics and places,title, dateline and body via regular expression searching using the well-defined xml style tags as defined by the lewis.dtd file included with the Corpus.

The documents are tokenized using the nltk.word_tokenize function with the results then passed through the clean() function that
reads the various parameter flags to determine which filters to apply to the resulting word before passing it on to create token,docId posting pairs.
The ensuing Document objects are encapsulated within a Corpus object which exists purely to store the the various Document objects as well as the file path
to the corpus as well as the compression parameters.

Once parsing is completed the Inverter object defined in the spimi.py file transforms the list of postings contained in the Corpus class into an iterator
and begins the inversion part of the algorithm. This is done via the index function that simply iterates over the token iterator
and creates a dictionary with the terms as keys with each docId in a posting appended to the list that represents the value paired to the key.
This dictionary is size constricted via the input parameter, with the dictionary being written to a new blockfile when the size limit is reached.
The process is completed until the token iterator is emptied.

From this point the Merger class is passed the list of blockfiles created by the inverter and begins the merger of all the block files into
a sorted master index file. This is done via the readline() iterator function native to python to return an iterator for each file.
This is to prevent filesystem and memory issues from arising from reading multiple files at the same time and allows us to step through
the files only when required. This is done via the BlockLine and BlockFile classes that contain helper functions to control the creation and merging
of each line entry to the master index file in a manner that prevents variable clutter that was observed early on in the development of this program.
This merger writes the sorted index file on a term by term basis to also prevent holding too many inverted indexes in memory at a given time.

Term Compression Table:
Each row also uses the compression parameter of hte rows above

Compression Technique|Token Count| Diff from Previous| Term Count| Diff from Previous| Execution Time|
No Compression | 3205582| N/A | 97370 | N/A | 28 seconds
Case-Folding | 3205582 | 0% | 80439 | -17% | 29 seconds
Digit-Removal | 3025594 | -5.5% | 50828 | -37% | 40 seconds
Stopword-Removal | 1773700 | -42% | 50666 | -.5% | 4 Minutes 41 seconds
Porter Stemming | 1773700 | 0% | 39778 | -21.5% | 6 Minutes 45 seconds


##Query Processing:
Example commandline:python query.py -o -q "Saskatchewan Quebec" -d -c -s
HELP DIALOG:
  -h, --help            show this help message and exit
  -a, --AND             Choose AND type query, if used with -o or --OR
                        parameter, supercedes it
  -o, --OR              Choose OR type query, if used with -a or --AND
                        parameter, is superceded by it
  -d, --digits          Enable digit removal on query terms
  -c, --case            Enable case folding on query terms
  -s, --stopwords       Enable stopword removal on query terms
  -m, --stemmer         Enable Porter Stemming on query terms
  -q QUERY, --query QUERY
                        Query Terms to search for, in the form "TERM TERM",
                        with each term separated by a space, and/or terms are
                        not required unless they are actual query terms


The query processor operates as a very simple script that splits the query terms and applies the required filter parameters.
The terms are then searched for in the master index file created by the Inverter class as described above and returns all docIds for each term.
These lists are then merged as appropriate based on the type of query (AND or OR), using either the builtin union or intersection methods provided by python.
The resulting set of docIds is then used to extract the articles with the desired ids from the raw corpus files. These articles
are then written to unique text files of the form {docID}.txt in the output folder to allow for ease of use for the user. The docIds are also printed
to the console to give the user a broad sense of the number of resulting articles for the query.

Issues:
Over the course of the development of this application a few issues were run into, mainly dealing with handling multiple variables across
loops and logic gates. This led me to create the BlockLine and BlockFile classes to be able to merge the utility from these variables
with a single call and handle the more complicated logic in a separate location that does not unduly increase the complexity of the main code base.
Another major bug was discovered when attempting to compare query results with other students. Upon execution of the queries it was discovered that
some of the basic logic controlling the parsing of the files was avoiding the vast mahority of each article and as such my final inverted index
was close to 1/100 of the size it should have been. A final issue had to deal with the memory restrictions, it was quickly discovered that if the simulated memory
size was too small that we would actually reach a hard limit imposed by the filesystem in regards to how many files can be open at the same time.
This does impose a soft restriction upon the execution of this application that in case of normal usage should not impede usage. The only cases where memory
would be restricted to such small sizes would require the user to manually edit the filesystem restrictions to allow for larger counts of open files.

Example Queries:
The following Queries were executed against an index created using case-folding, digit-removal and stopword removal compressions.
San or Carter:
10058
10252
10460
10558
10662
10691
10811
10998
11042
11114
11118
11133
11330
11389
11533
11863
12066
12072
12136
12160
12209
12277
12443
12531
12667
12677
13145
13147
1316
13235
1347
13540
13877
1402
14888
14921
14938
15158
15240
15274
15443
15467
15473
15484
15699
1582
15946
16071
16235
16887
17023
17325
17363
17490
17560
17676
17680
17719
1789
17974
18005
18075
18101
18138
18157
18196
18341
18342
18438
18962
19038
19205
19432
19828
1988
19890
19896
1993
19950
20236
20250
20614
20897
2128
21291
21292
21308
215
2389
2444
2447
2534
2740
3038
3055
316
3281
3367
3380
3400
3521
3561
367
3677
3725
3805
3981
3992
4181
4425
4590
4622
4730
4925
4934
5094
5163
5226
5465
5525
5609
5719
5730
6278
6340
641
67
6766
7040
7050
7052
7061
7144
725
7306
7366
7781
7840
7995
805
8085
8091
8130
8237
8352
854
863
8886
8914
965
9721
979
9826
9918
9932

President AND Carter
10252
11118
11330
13540
16887
17023
17325
17363
18005
19432
20614
5465
854
965

Quebec
1072
1082
11157
11303
11454
11624
11910
12199
12420
12489
12641
12651
12963
13757
14642
14728
14730
14871
14902
15166
15623
15932
15988
1607
17622
17632
17855
17856
17995
18093
18217
18252
18671
18673
18715
18730
18868
19126
19225
19717
1992
19937
19959
20790
20946
21004
21338
21341
2646
2655
2782
2880
3160
3625
3704
3898
3962
4073
414
421
4222
4242
4354
5512
6207
6742
7424
7476
7724
7737
79
838
8482
8948
9642

TODO INSERT COMPARISONS WITH CAIO AND ERIC

#Sample Queries:
Done with case folding, digit and stopwords
## Jimmy AND Carter
13540
20614
12136
19432
18005
17023

## Jimmy OR Carter
12677
20614
7052
18962
5525
18438
15473
17325
3380
15158
1993
21308
11330
1988
965
10252
17363
18005
854
7061
5465
13540
2534
19432
11114
11118
12136
16887
17023

## Green AND Party
21577

## Green OR Party
4096
8193
5124
13318
17415
15369
17419
12300
15373
15375
18449
14357
13564
17432
17433
2074
28
9247
18464
12322
13347
14342
19495
5161
21547
6188
6190
15408
9265
10290
9907
19508
17461
9275
60
13323
21572
19525
4166
21575
21577
20555
9292
14419
2132
17934
5208
15450
14427
15452
15453
19551
15456
5221
13414
1129
13419
13420
15470
9328
2162
2163
3188
19588
3205
13446
10379
7308
5262
12431
13458
8342
4247
12440
14874
9689
17573
5289
17583
11442
2228
9402
10271
15549
21536
6345
5325
19662
8405
5334
13527
6360
14635
5338
219
222
18469
1249
226
19683
20860
234
13548
9126
7549
3313
16409
10486
7415
18682
6395
6396
6400
8450
263
13576
17681
275
17966
20764
18138
6430
13606
19751
2347
8493
8496
308
7477
13627
2364
13629
14654
319
14809
12612
3397
20231
337
338
9774
6899
345
16732
2404
7525
2406
13671
12655
7536
14739
14710
11742
3451
13692
10621
16770
16774
16777
17803
16780
7651
16787
10646
17305
19867
12701
3488
8091
5190
10666
428
3502
13725
15795
17222
13752
10682
14780
12737
18507
4548
1477
14412
19191
16844
7630
17874
2467
16292
10355
9466
13790
13733
18915
17893
14825
14826
16876
10733
3567
8691
5622
13417
19960
13396
20986
6052
2556
10752
11779
16902
9739
3597
12814
8727
4634
20911
19034
9761
6698
9479
2606
10799
17970
8627
14905
1594
11837
4670
19898
4674
2627
9797
4705
12876
12878
12879
19024
19027
3670
20056
15962
20061
19039
7777
7779
14950
14951
20075
4719
4721
12916
9847
9848
21118
4736
4738
21123
14982
5774
17040
19091
1685
17047
10863
17055
11768
13993
13995
17070
17072
8307
8884
15033
19134
704
9921
707
8904
9929
14030
10268
19157
1753
20186
2786
14631
6156
16115
7927
14976
18731
7941
2823
16137
6927
17170
17172
17075
4887
13082
13084
21508
11397
6945
17188
12069
3878
14757
3885
18222
3549
1842
16181
9183
16198
19566
15372
967
14819
1880
16727
12773
17249
16226
4070
871
17259
1900
7022
1906
17043
17272
16211
15228
7043
12438
13190
8073
10123
21276
9108
2965
2967
19353
20379
2972
13637
11172
1957
5030
11175
11176
13534
17012
9140
12750
4026
9153
8133
18375
13257
8139
13260
19405
5070
6989
12792
13277
18597
10210
18403
19430
19432
11243
11245
15342
1916
18417
5107
10230
7849
17402
5117
6143

## Innovations AND in AND telecommunication
NONE

## Innovations OR in OR telecommunication
16128
6535
19016
5386
7051
21550
19035
12188
3552
8483
12459
5230
12143
21555
17460
247
3192